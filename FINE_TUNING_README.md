# üéØ Fine-tuning Pipeline - AI Training Platform

## üìã Overview

Fine-tuning Pipeline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI Training Platform ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á **Azure OpenAI** ‡πÅ‡∏•‡∏∞ **OpenSource Models** ‡∏û‡∏£‡πâ‡∏≠‡∏° GIF export ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö review

## üöÄ Features

### ‚úÖ **Azure OpenAI Fine-tuning**
- Dataset preparation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Azure OpenAI format
- Complete workflow orchestration
- Model deployment ‡πÅ‡∏•‡∏∞ testing
- Quality evaluation metrics

### ‚úÖ **OpenSource Model Demo**
- Local model inference
- Real-time conversation demo
- GIF export ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö review
- Multiple model support

### ‚úÖ **Quality Assurance**
- Dataset quality filtering
- Train/validation split
- Performance benchmarking
- Comprehensive testing

## üìÅ Project Structure

```
project/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ azure_fine_tuning_prep.py      # Dataset preparation
‚îÇ   ‚îú‚îÄ‚îÄ azure_fine_tuning_orchestrator.py  # Azure workflow
‚îÇ   ‚îú‚îÄ‚îÄ opensource_model_demo.py       # OpenSource demo
‚îÇ   ‚îî‚îÄ‚îÄ test_fine_tuning_pipeline.py   # Testing framework
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ azure_fine_tuning/             # Azure format datasets
‚îÇ   ‚îú‚îÄ‚îÄ processed/                     # Processed datasets
‚îÇ   ‚îî‚îÄ‚îÄ enhanced/                      # Enhanced datasets
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îî‚îÄ‚îÄ gifs/                          # GIF exports
‚îú‚îÄ‚îÄ test_outputs/                      # Test results
‚îú‚îÄ‚îÄ requirements_fine_tuning.txt       # Dependencies
‚îú‚îÄ‚îÄ test_fine_tuning.sh               # Test script
‚îî‚îÄ‚îÄ FINE_TUNING_README.md             # This file
```

## üõ†Ô∏è Installation

### 1. **Install Dependencies**

```bash
# Install fine-tuning requirements
pip install -r requirements_fine_tuning.txt

# ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß
pip install torch transformers datasets
pip install azure-identity azure-ai-ml azure-storage-blob
pip install openai pillow imageio fastapi uvicorn
```

### 2. **Azure Setup** (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Azure Fine-tuning)

```bash
# Login to Azure
az login

# Set subscription
az account set --subscription <your-subscription-id>

# Create resource group
az group create --name <resource-group> --location eastus

# Create Azure OpenAI resource
az cognitiveservices account create \
    --name <openai-resource> \
    --resource-group <resource-group> \
    --kind OpenAI \
    --sku S0 \
    --location eastus
```

### 3. **Environment Variables**

```bash
# Azure OpenAI
export AZURE_OPENAI_ENDPOINT="https://<resource>.openai.azure.com/"
export AZURE_OPENAI_API_KEY="<your-api-key>"
export AZURE_SUBSCRIPTION_ID="<subscription-id>"
export AZURE_RESOURCE_GROUP="<resource-group>"
export AZURE_WORKSPACE_NAME="<workspace-name>"

# Storage
export AZURE_STORAGE_ACCOUNT="<storage-account>"
```

## üéØ Usage Examples

### 1. **Dataset Preparation**

```bash
# ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Azure fine-tuning
python3 scripts/azure_fine_tuning_prep.py \
    --output-dir data/azure_fine_tuning \
    --test-size 0.2
```

**Output:**
- `train_data.jsonl` - Training data
- `validation_data.jsonl` - Validation data
- `dataset_metadata.json` - Dataset statistics

### 2. **OpenSource Model Demo**

```bash
# ‡∏™‡∏≤‡∏ò‡∏¥‡∏ï OpenSource model ‡∏û‡∏£‡πâ‡∏≠‡∏° GIF export
python3 scripts/opensource_model_demo.py \
    --model "microsoft/DialoGPT-medium" \
    --prompts "Hello!" "How are you?" "Tell me a joke" \
    --output-gif "demo_conversation.gif"
```

**Output:**
- `demo_conversation.gif` - Animated conversation
- `demo_results.json` - Test results

### 3. **Azure Fine-tuning Workflow**

```bash
# ‡∏£‡∏±‡∏ô complete Azure fine-tuning workflow
python3 scripts/azure_fine_tuning_orchestrator.py \
    --subscription-id $AZURE_SUBSCRIPTION_ID \
    --resource-group $AZURE_RESOURCE_GROUP \
    --workspace-name $AZURE_WORKSPACE_NAME \
    --openai-endpoint $AZURE_OPENAI_ENDPOINT \
    --openai-api-key $AZURE_OPENAI_API_KEY \
    --storage-account $AZURE_STORAGE_ACCOUNT \
    --data-file data/azure_fine_tuning/train_data.jsonl \
    --model-name "gpt-35-turbo" \
    --deployment-name "my-fine-tuned-model"
```

### 4. **Complete Testing**

```bash
# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö pipeline ‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
./test_fine_tuning.sh

# ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ Python script
python3 scripts/test_fine_tuning_pipeline.py --test-dir test_outputs
```

## üìä Dataset Format

### **Azure OpenAI Format (JSONL)**

```json
{"messages": [{"role": "user", "content": "Hello!"}, {"role": "assistant", "content": "Hi there! How can I help you today?"}]}
{"messages": [{"role": "user", "content": "What's the weather like?"}, {"role": "assistant", "content": "I don't have access to real-time weather data, but I can help you find weather information online!"}]}
```

### **Input Format Support**

- **Conversations**: `{"conversations": [{"from": "human", "value": "..."}, {"from": "gpt", "value": "..."}]}`
- **Instruction-Response**: `{"instruction": "...", "response": "..."}`
- **Prompt-Completion**: `{"prompt": "...", "completion": "..."}`

## üé¨ GIF Export Features

### **OpenSource Model Demo GIF**

- **Real-time Conversation**: ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á user ‡πÅ‡∏•‡∏∞ model
- **Generation Time**: ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á response
- **Quality Metrics**: ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á response
- **Export Options**: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô GIF ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö review

### **GIF Configuration**

```python
# ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á GIF settings
demo = OpenSourceModelDemo("microsoft/DialoGPT-medium")
demo.frame_delay = 0.5  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏≠‡∏á animation
demo.gif_frames = []    # ‡πÄ‡∏Å‡πá‡∏ö frames

# ‡∏™‡∏£‡πâ‡∏≤‡∏á custom frame
demo.add_frame_to_gif("Custom text frame")
demo.save_gif("custom_demo.gif")
```

## üîß Configuration

### **Azure Fine-tuning Hyperparameters**

```python
hyperparameters = {
    "n_epochs": 3,                    # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epochs
    "batch_size": 1,                  # Batch size
    "learning_rate_multiplier": 1.0   # Learning rate multiplier
}
```

### **Quality Filtering Settings**

```python
# Dataset quality thresholds
min_length = 50        # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
max_length = 4000      # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
min_response_length = 20  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß response ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥
```

### **Model Selection**

```python
# Azure OpenAI Models
azure_models = [
    "gpt-35-turbo",
    "gpt-4",
    "gpt-4-turbo"
]

# OpenSource Models
opensource_models = [
    "microsoft/DialoGPT-small",
    "microsoft/DialoGPT-medium",
    "microsoft/DialoGPT-large",
    "facebook/opt-350m",
    "facebook/opt-1.3b"
]
```

## üìà Performance Metrics

### **Dataset Quality Metrics**

- **Total Conversations**: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
- **Train/Validation Split**: ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• training/validation
- **Average Message Length**: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
- **Quality Score**: ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á dataset

### **Model Performance Metrics**

- **Generation Time**: ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á response
- **Response Quality**: ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á response
- **Token Usage**: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô tokens ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
- **Cost Analysis**: ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢

## üß™ Testing Framework

### **Test Coverage**

1. **Dataset Preparation Test**
   - Data loading ‡πÅ‡∏•‡∏∞ validation
   - Format conversion
   - Quality filtering
   - Train/validation split

2. **OpenSource Model Test**
   - Model loading
   - Response generation
   - GIF creation
   - Performance measurement

3. **Azure Orchestrator Test**
   - Storage setup
   - Data upload
   - Job creation
   - Model deployment

4. **Web Application Test**
   - API endpoints
   - Health checks
   - User interface

### **Running Tests**

```bash
# Run all tests
./test_fine_tuning.sh

# Run specific test
python3 scripts/test_fine_tuning_pipeline.py --test-dir test_outputs

# Check test results
cat test_outputs/test_results.json
```

## üöÄ Production Deployment

### **Azure Production Setup**

1. **Resource Scaling**
   ```bash
   # Scale up Azure resources
   az cognitiveservices account update \
       --name <resource> \
       --resource-group <group> \
       --sku S1
   ```

2. **Monitoring Setup**
   ```bash
   # Enable monitoring
   az monitor diagnostic-settings create \
       --resource <resource-id> \
       --name "fine-tuning-monitoring" \
       --logs '[{"category": "AuditLogs", "enabled": true}]'
   ```

3. **Security Configuration**
   ```bash
   # Enable private endpoints
   az network private-endpoint create \
       --name "openai-private-endpoint" \
       --resource-group <group> \
       --vnet-name <vnet> \
       --subnet <subnet> \
       --private-connection-resource-id <resource-id>
   ```

### **OpenSource Production Setup**

1. **Model Optimization**
   ```python
   # Quantization for production
   from transformers import AutoModelForCausalLM
   
   model = AutoModelForCausalLM.from_pretrained("microsoft/DialoGPT-medium")
   model = torch.quantization.quantize_dynamic(model, {torch.nn.Linear}, dtype=torch.qint8)
   ```

2. **Caching Setup**
   ```python
   # Response caching
   import redis
   
   redis_client = redis.Redis(host='localhost', port=6379, db=0)
   
   def get_cached_response(prompt):
       cache_key = f"response:{hash(prompt)}"
       return redis_client.get(cache_key)
   ```

## üìö Troubleshooting

### **Common Issues**

1. **Azure Authentication Error**
   ```bash
   # Solution: Set up Azure credentials
   az login
   az account set --subscription <subscription-id>
   ```

2. **Model Loading Error**
   ```bash
   # Solution: Install correct dependencies
   pip install torch transformers --index-url https://download.pytorch.org/whl/cu118
   ```

3. **GIF Creation Error**
   ```bash
   # Solution: Install imageio dependencies
   pip install imageio imageio-ffmpeg
   ```

4. **Memory Issues**
   ```python
   # Solution: Use smaller models or enable gradient checkpointing
   model.gradient_checkpointing_enable()
   ```

### **Debug Mode**

```bash
# Enable debug logging
export LOG_LEVEL=DEBUG
python3 scripts/azure_fine_tuning_prep.py --debug
```

## ü§ù Contributing

### **Development Setup**

1. **Fork Repository**
2. **Create Feature Branch**
3. **Add Tests**
4. **Submit Pull Request**

### **Code Standards**

- Follow PEP 8 style guidelines
- Add type hints to all functions
- Include comprehensive docstrings
- Write unit tests for new features

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üÜò Support

### **Documentation**
- [Azure OpenAI Documentation](https://docs.microsoft.com/en-us/azure/cognitive-services/openai/)
- [Transformers Documentation](https://huggingface.co/docs/transformers/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)

### **Community**
- GitHub Issues: [Report bugs](https://github.com/your-repo/issues)
- Discussions: [Ask questions](https://github.com/your-repo/discussions)

---

## üéâ **Ready to Fine-tune!**

Fine-tuning Pipeline ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß! 

**‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:**
```bash
./test_fine_tuning.sh
```

**‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:**
```bash
python3 scripts/opensource_model_demo.py --help
python3 scripts/azure_fine_tuning_prep.py --help
```

**Happy Fine-tuning! üöÄ**
