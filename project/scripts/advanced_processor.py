#!/usr/bin/env python3
import json
import re
import os
from collections import defaultdict, Counter

class PromptFilter:
    def __init__(self, min_length=10, max_length=1000, min_tokens=3, max_tokens=300):
        self.min_length = min_length
        self.max_length = max_length
        self.min_tokens = min_tokens
        self.max_tokens = max_tokens
    
    def count_tokens(self, text):
        """‡∏ô‡∏±‡∏ö tokens ‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì"""
        return len(re.findall(r'\w+', text))
    
    def is_valid_prompt(self, user_input, target_prompt):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ prompt ‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        checks = {
            "user_length": self.min_length <= len(user_input) <= self.max_length,
            "target_length": self.min_length <= len(target_prompt) <= self.max_length,
            "user_tokens": self.min_tokens <= self.count_tokens(user_input) <= self.max_tokens,
            "target_tokens": self.min_tokens <= self.count_tokens(target_prompt) <= self.max_tokens,
            "not_empty": user_input.strip() and target_prompt.strip(),
            "no_special_chars": not any(char in user_input for char in ['<', '>', '{', '}', '[', ']'])
        }
        
        return all(checks.values()), checks

class IntentClassifier:
    def __init__(self):
        self.intent_patterns = {
            "instruction": [
                r"^(write|create|make|build|implement|design|develop)",
                r"^(how to|how do|how can)",
                r"(step by step|tutorial|guide|instructions)",
                r"^(explain|describe|define|clarify)"
            ],
            "question": [
                r"^(what|why|when|where|which|who)",
                r"^(is|are|can|could|would|should|do|does)",
                r"\?$"
            ],
            "roleplay": [
                r"^(act as|you are|role|pretend|imagine)",
                r"(assistant|teacher|expert|coach|advisor)",
                r"(persona|character|role-play)"
            ],
            "code": [
                r"(function|class|method|algorithm)",
                r"(python|javascript|java|c\+\+|code)",
                r"(programming|coding|software|debug)"
            ],
            "conversation": [
                r"^(hi|hello|hey|good|thanks)",
                r"(chat|talk|discuss|conversation)",
                r"(opinion|think|feel|suggest)"
            ]
        }
    
    def classify_intent(self, user_input):
        """‡∏à‡∏≥‡πÅ‡∏ô‡∏Å intent ‡∏Ç‡∏≠‡∏á prompt"""
        text = user_input.lower().strip()
        
        intent_scores = defaultdict(int)
        
        for intent, patterns in self.intent_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text):
                    intent_scores[intent] += 1
        
        if not intent_scores:
            return "general"
        
        return max(intent_scores, key=intent_scores.get)

class DatasetProcessor:
    def __init__(self):
        self.filter = PromptFilter()
        self.classifier = IntentClassifier()
        self.stats = {
            "total_processed": 0,
            "filtered_out": 0,
            "by_intent": defaultdict(int),
            "by_source": defaultdict(int),
            "filter_reasons": defaultdict(int)
        }
    
    def process_dataset(self, input_folder, output_file="enhanced_dataset.jsonl"):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• datasets ‡∏û‡∏£‡πâ‡∏≠‡∏° filtering ‡πÅ‡∏•‡∏∞ intent classification"""
        
        print("üîç Processing datasets with advanced filtering...")
        print("=" * 60)
        
        processed_records = []
        
        # ‡πÇ‡∏´‡∏•‡∏î manifest
        manifest_path = "data/dataset_manifest.json"
        manifest = {}
        if os.path.exists(manifest_path):
            with open(manifest_path, "r", encoding="utf-8") as f:
                manifest = json.load(f)
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        for filename in os.listdir(input_folder):
            if not filename.endswith(('.json', '.jsonl')):
                continue
                
            filepath = os.path.join(input_folder, filename)
            dataset_name = filename.split('.')[0]
            
            print(f"üìÑ Processing {dataset_name}...")
            
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            records = self.load_dataset_file(filepath)
            
            for record in records:
                self.stats["total_processed"] += 1
                self.stats["by_source"][dataset_name] += 1
                
                user_input = record.get("user_input", "")
                target_prompt = record.get("target_prompt", "")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
                is_valid, checks = self.filter.is_valid_prompt(user_input, target_prompt)
                
                if not is_valid:
                    self.stats["filtered_out"] += 1
                    for check, passed in checks.items():
                        if not passed:
                            self.stats["filter_reasons"][check] += 1
                    continue
                
                # ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å intent
                intent = self.classifier.classify_intent(user_input)
                self.stats["by_intent"][intent] += 1
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata
                enhanced_record = {
                    "user_input": user_input,
                    "target_prompt": target_prompt,
                    "intent": intent,
                    "source": dataset_name,
                    "user_tokens": self.filter.count_tokens(user_input),
                    "target_tokens": self.filter.count_tokens(target_prompt),
                    "user_length": len(user_input),
                    "target_length": len(target_prompt)
                }
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏° metadata ‡∏à‡∏≤‡∏Å manifest
                if dataset_name in manifest.get("datasets", {}):
                    enhanced_record["source_quality"] = manifest["datasets"][dataset_name].get("quality", "unknown")
                
                processed_records.append(enhanced_record)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        with open(output_file, "w", encoding="utf-8") as f:
            for record in processed_records:
                f.write(json.dumps(record, ensure_ascii=False) + "\n")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
        self.generate_report(processed_records, output_file)
        
        return processed_records
    
    def load_dataset_file(self, filepath):
        """‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå dataset ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö"""
        records = []
        
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                if filepath.endswith('.jsonl'):
                    for line in f:
                        if line.strip():
                            records.append(json.loads(line))
                else:
                    data = json.load(f)
                    if isinstance(data, list):
                        records = data
                    elif isinstance(data, dict) and "data" in data:
                        records = data["data"]
        except Exception as e:
            print(f"‚ö†Ô∏è  Error loading {filepath}: {e}")
        
        return records
    
    def generate_report(self, processed_records, output_file):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•"""
        
        print(f"\nüìä Processing Report")
        print("=" * 60)
        print(f"Total processed: {self.stats['total_processed']}")
        print(f"Valid records: {len(processed_records)}")
        print(f"Filtered out: {self.stats['filtered_out']}")
        print(f"Success rate: {len(processed_records)/self.stats['total_processed']*100:.1f}%")
        
        print(f"\nüéØ Records by Intent:")
        for intent, count in sorted(self.stats["by_intent"].items(), key=lambda x: x[1], reverse=True):
            percentage = count / len(processed_records) * 100
            print(f"  {intent}: {count} ({percentage:.1f}%)")
        
        print(f"\nüìÅ Records by Source:")
        for source, count in sorted(self.stats["by_source"].items(), key=lambda x: x[1], reverse=True):
            valid_count = sum(1 for r in processed_records if r["source"] == source)
            success_rate = valid_count / count * 100 if count > 0 else 0
            print(f"  {source}: {valid_count}/{count} ({success_rate:.1f}%)")
        
        if self.stats["filter_reasons"]:
            print(f"\n‚ùå Top Filter Reasons:")
            for reason, count in sorted(self.stats["filter_reasons"].items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"  {reason}: {count}")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå
        report = {
            "summary": {
                "total_processed": self.stats["total_processed"],
                "valid_records": len(processed_records),
                "filtered_out": self.stats["filtered_out"],
                "success_rate": len(processed_records)/self.stats["total_processed"]*100
            },
            "by_intent": dict(self.stats["by_intent"]),
            "by_source": dict(self.stats["by_source"]),
            "filter_reasons": dict(self.stats["filter_reasons"]),
            "output_file": output_file
        }
        
        with open("processing_report.json", "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\n‚úÖ Enhanced dataset saved to: {output_file}")
        print(f"üìã Report saved to: processing_report.json")

def main():
    processor = DatasetProcessor()
    processor.process_dataset("data/raw", "enhanced_dataset.jsonl")

if __name__ == "__main__":
    main()
